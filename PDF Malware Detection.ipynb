{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a2be88-b74c-49c7-9f3e-0792101fb4e7",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d5fd17-431a-4d15-b511-26c1192de8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tqdm\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "import re\n",
    "import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def bold(string):\n",
    "    display(Markdown(\"**\" + string + \"**\"))\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be9dc2-b0bf-43b2-8bb8-54fec2066421",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163eb08-9053-4ea8-b40d-0ee314c8c7b2",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8542e25-c0e7-4521-b282-456580007cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pdf-dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fcc197-ef1b-485a-979e-f9782c73308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3444198-eaf5-472d-a69c-072a4a192288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(data):\n",
    "    bold(\" SHAPE \".center(50, \"#\"))\n",
    "    print(\"ROWS: {}\".format(data.shape[0]))\n",
    "    print(\"COLUMNS: {}\".format(data.shape[1]))\n",
    "    bold(\" TYPES \".center(50, \"#\"))\n",
    "    print(data.dtypes)\n",
    "    bold(\" MISSING VALUES \".center(50, \"#\"))\n",
    "    print(data.isnull().sum())\n",
    "    bold(\" DUPLICATED VALUES \".center(50, \"#\"))\n",
    "    print(\"NUMBER OF DUPLICATED VALUES: {}\".format(data.duplicated().sum()))\n",
    "    bold(\" MEMORY USAGE \".center(50, \"#\"))\n",
    "    buf = io.StringIO()\n",
    "    data.info(buf=buf)\n",
    "    info = buf.getvalue().split(\"\\n\")[-2].split(\":\")[1].strip()\n",
    "    print(\"Memory Usage: {}\".format(info))\n",
    "    bold(\" DESCRIBE \".center(50, \"#\"))\n",
    "    display(data.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a72af-d7a2-471d-8f7f-7e77893aa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e7edf-9beb-4497-9d59-d503b386ffc7",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa50a957-7387-4693-a901-370d0655604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ececc-11ce-4e15-8b66-10acb7cb064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9dd73a-32cf-419a-8804-564044617af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaecf50-e7ab-40ad-8c06-6674492eb34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = self.texts[item]\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489796a-e2a5-476d-866d-1b8752f1bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, split_size):\n",
    "    perm = np.random.permutation(df.index)\n",
    "    train_end = int(train_size * len(df.index))\n",
    "    validate_end = int(((1 - split_size) / 2) * len(df.index)) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd4520-76ee-4846-9cf5-4daf36b1e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.9\n",
    "df_train, df_validation, df_test = train_validate_test_split(df, train_size)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_validation = df_validation.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"Full dataset: {df.shape[0]}\")\n",
    "print(f\"Train dataset: {df_train.shape[0]}\")\n",
    "print(f\"Valid dataset: {df_validation.shape[0]}\")\n",
    "print(f\"Test dataset: {df_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e02dead-86ba-494f-ae16-10727bd18859",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = CustomDataset(df_train[\"text\"].to_numpy(), df_train[\"label\"].to_numpy(), tokenizer)\n",
    "validation_set = CustomDataset(df_validation[\"text\"].to_numpy(), df_validation[\"label\"].to_numpy(), tokenizer)\n",
    "testing_set = CustomDataset(df_test[\"text\"].to_numpy(), df_test[\"label\"].to_numpy(), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6e5d4-2aa0-4bef-8a1d-4d2e0193e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d80783-40e8-4200-9c81-2a629e083f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": TRAIN_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "valid_params = {\"batch_size\": VALID_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "test_params = {\"batch_size\": TEST_BATCH_SIZE, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "validation_loader = DataLoader(validation_set, **valid_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c874a-6be4-4d02-b207-057cb730749a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6e8d3-3767-48c0-84ca-a13dea608985",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-05\n",
    "EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6137a-a24a-4933-baab-c9a77d73133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "total_steps = len(training_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfe0da-a0d1-46da-b17a-cc343cc9d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, scheduler, device):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm.tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,  labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6a2ec-f76f-4bce-ae49-a7c5683333c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, service):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm.tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32479ace-30f8-465a-8d10-2f7d30bdb78e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec39f141-f3f7-43ee-9415-b923a4772e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(model, training_loader, optimizer, scheduler, device)\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(model, validation_loader, device)\n",
    "    print(f'Val loss {val_loss} accuracy {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6f4fc-63d1-4d1b-81ae-46ce30cea214",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e363827-1221-4559-bde2-418a8a2bf4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "model = model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for d in testing_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58158d45-687e-4b4a-80e7-9c8f744fdd1a",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f068f-b6cf-475f-b598-bbad6ecd4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_precision_score = precision_score(y_true, y_pred, average='macro')\n",
    "model_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "model_recall_score = recall_score(y_true, y_pred, average='macro')\n",
    "model_accuracy_score = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision Score = {model_precision_score * 100:.2f}%\")\n",
    "print(f\"F1 Score = {model_f1_score * 100:.2f}%\")\n",
    "print(f\"Recall Score = {model_recall_score * 100:.2f}%\")\n",
    "print(f\"Accuracy Score = {model_accuracy_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2fc681-a52b-4fbe-99eb-9608d9cd813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=[\"Benign\", \"Malicious\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c010f24-8012-4890-b9b9-3a2de5cc95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm, show_absolute=True, show_normed=True, colorbar=True, class_names=[\"Benign\", \"Malicious\"])\n",
    "plt.title(\"BERT - Confusion Matrix\")\n",
    "plt.show("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d232fa3-46af-4383-a193-ab25563ecdb8",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad3d39-1656-4e41-be74-d2a52cb5dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = str(f.read())\n",
    "        data = ' '.join(data[i:i+4] for i in range(0, len(data), 4))\n",
    "        data = bytes(data, \"utf-8\")\n",
    "\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473019e9-2020-4091-9339-0e7b9dc4a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_file(filepath):\n",
    "    data = extract_features(filepath)\n",
    "    encoding = tokenizer(data)\n",
    "    input_ids = torch.tensor(encoding[\"input_ids\"]).to(device)\n",
    "    attention_mask = torch.tensor(encoding[\"attention_mask\"]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids.unsqueeze(0), attention_mask.unsqueeze(0))\n",
    "\n",
    "    pred = np.argmax(outputs[0].to(\"cpu\").numpy())\n",
    "    if pred == 0:\n",
    "        print(\"This file is benign.\")\n",
    "    else:\n",
    "        print(\"This file is malicious.\")\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86edebd-7988-4d45-aee4-bc5d8b02f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./data/test.pdf\"\n",
    "result = test_file(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
